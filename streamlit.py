import streamlit as st
import mlflow
import mlflow.sklearn
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
import numpy as np
import matplotlib.pyplot as plt
import random
import pandas as pd
# Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.title("Ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay MNIST v·ªõi Streamlit v√† MLflow")

# ------------------------
# B∆∞·ªõc 1: X·ª≠ l√Ω d·ªØ li·ªáu
# ------------------------
st.header("1. X·ª≠ l√Ω d·ªØ li·ªáu")

# Ki·ªÉm tra n·∫øu d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong session_state ch∆∞a
if "mnist_loaded" not in st.session_state:
    st.write("ƒêang t·∫£i d·ªØ li·ªáu MNIST...")
    mnist = fetch_openml('mnist_784', version=1, as_frame=False)
    X, y = mnist.data / 255.0, mnist.target.astype(int)
    # L∆∞u d·ªØ li·ªáu v√†o session_state ƒë·ªÉ d√πng l·∫°i
    st.session_state.X = X
    st.session_state.y = y
    st.session_state.mnist_loaded = True
    st.write("D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i v√† l∆∞u th√†nh c√¥ng!")
else:
    st.write("D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i t·ª´ b·ªô nh·ªõ!")
    X = st.session_state.X
    y = st.session_state.y

# In ra s·ªë l∆∞·ª£ng m·∫´u c·ªßa t·ª´ng label trong d·ªØ li·ªáu g·ªëc
unique_labels, counts = np.unique(y, return_counts=True)
label_counts = {int(k): int(v) for k, v in zip(unique_labels, counts)}
st.write("S·ªë l∆∞·ª£ng m·ªói label trong d·ªØ li·ªáu g·ªëc:", label_counts)

# Hi·ªÉn th·ªã m·ªôt v√†i h√¨nh ·∫£nh minh h·ªça v√† l∆∞u v√†o session_state
st.subheader("V√≠ d·ª• m·ªôt v√†i h√¨nh ·∫£nh minh h·ªça")
if "example_images" not in st.session_state:
    indices = random.sample(range(len(X)), 5)
    st.session_state.example_images = indices
else:
    indices = st.session_state.example_images

fig, axs = plt.subplots(1, 5, figsize=(12, 3))
for i, idx in enumerate(indices):
    img = X[idx].reshape(28, 28)
    axs[i].imshow(img, cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(f"Label: {y[idx]}")
st.pyplot(fig)

# ------------------------
# B∆∞·ªõc 2: Chia t√°ch d·ªØ li·ªáu
# ------------------------
st.header("2. Chia t√°ch d·ªØ li·ªáu")
test_size = st.slider("Ch·ªçn t·ª∑ l·ªá d·ªØ li·ªáu Test", 0.1, 0.5, 0.2, 0.05)
valid_size = st.slider("Ch·ªçn t·ª∑ l·ªá d·ªØ li·ªáu Validation t·ª´ Train", 0.1, 0.3, 0.2, 0.05)

if st.button("Chia t√°ch d·ªØ li·ªáu"):
    X_train_full, X_test, y_train_full, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    X_train, X_valid, y_train, y_valid = train_test_split(
        X_train_full, y_train_full, test_size=valid_size, random_state=42, stratify=y_train_full
    )
    st.session_state.X_train = X_train
    st.session_state.X_valid = X_valid
    st.session_state.X_test = X_test
    st.session_state.y_train = y_train
    st.session_state.y_valid = y_valid
    st.session_state.y_test = y_test
    st.session_state.data_split_done = True

# Hi·ªÉn th·ªã th√¥ng tin chia t√°ch n·∫øu ƒë√£ th·ª±c hi·ªán
if st.session_state.get("data_split_done", False):
    st.write(f"D·ªØ li·ªáu Train: {st.session_state.X_train.shape}")
    st.write(f"D·ªØ li·ªáu Validation: {st.session_state.X_valid.shape}")
    st.write(f"D·ªØ li·ªáu Test: {st.session_state.X_test.shape}")

# ------------------------
# B∆∞·ªõc 2b: C√¢n b·∫±ng d·ªØ li·ªáu (Oversampling)
# ------------------------
if "X_train" in st.session_state and "y_train" in st.session_state:
    st.subheader("TƒÉng c∆∞·ªùng d·ªØ li·ªáu (Oversampling)")
    balance_multiplier = st.slider("H·ªá s·ªë tƒÉng c∆∞·ªùng", 1.0, 3.0, 1.0, 0.1, key="balance_multiplier")
    if st.button("C√¢n b·∫±ng d·ªØ li·ªáu"):
        from imblearn.over_sampling import RandomOverSampler
        unique_train, counts_train = np.unique(st.session_state.y_train, return_counts=True)
        max_count = int(max(counts_train))
        target_count = int(max_count * balance_multiplier)
        sampling_strategy = {label: target_count for label in unique_train}
        ros = RandomOverSampler(sampling_strategy=sampling_strategy, random_state=42)
        X_train_bal, y_train_bal = ros.fit_resample(st.session_state.X_train, st.session_state.y_train)
        st.session_state.X_train_bal = X_train_bal
        st.session_state.y_train_bal = y_train_bal
        unique_labels_bal, counts_bal = np.unique(y_train_bal, return_counts=True)
        label_counts_bal = {int(k): int(v) for k, v in zip(unique_labels_bal, counts_bal)}
        st.session_state.balance_info = label_counts_bal

# Hi·ªÉn th·ªã th√¥ng tin c√¢n b·∫±ng n·∫øu c√≥
if "balance_info" in st.session_state:
    st.write("Sau khi c√¢n b·∫±ng, s·ªë l∆∞·ª£ng m·ªói label trong t·∫≠p hu·∫•n luy·ªán:", st.session_state.balance_info)

# ------------------------
# B∆∞·ªõc 3: Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh
# ------------------------
st.header("3. Hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh")
model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh", ["Decision Tree", "SVM"], key="model_choice")

if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
    if "X_train" not in st.session_state or "X_valid" not in st.session_state:
        st.error("B·∫°n c·∫ßn chia t√°ch d·ªØ li·ªáu tr∆∞·ªõc!")
        st.stop()
    # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ c√¢n b·∫±ng n·∫øu c√≥, ng∆∞·ª£c l·∫°i d√πng d·ªØ li·ªáu g·ªëc
    if "X_train_bal" in st.session_state and "y_train_bal" in st.session_state:
        X_train_used = st.session_state.X_train_bal
        y_train_used = st.session_state.y_train_bal
    else:
        X_train_used = st.session_state.X_train
        y_train_used = st.session_state.y_train
    X_valid = st.session_state.X_valid
    y_valid = st.session_state.y_valid

    with mlflow.start_run():
        if model_choice == "Decision Tree":
            st.session_state.model = DecisionTreeClassifier(max_depth=20, random_state=42)
        else:
            scaler = StandardScaler()
            X_train_used_scaled = scaler.fit_transform(X_train_used)
            X_valid_scaled = scaler.transform(X_valid)
            st.session_state.scaler = scaler
            st.session_state.model = SVC(kernel='rbf', C=10, gamma=0.01, random_state=42)
        if model_choice == "SVM":
            st.session_state.model.fit(X_train_used_scaled, y_train_used)
            y_pred = st.session_state.model.predict(X_valid_scaled)
        else:
            st.session_state.model.fit(X_train_used, y_train_used)
            y_pred = st.session_state.model.predict(X_valid)
        st.session_state.trained_model_name = model_choice
        st.session_state.train_accuracy = accuracy_score(y_valid, y_pred)
        st.session_state.train_report = classification_report(y_valid, y_pred)
        mlflow.log_param("model", model_choice)
        mlflow.log_metric("accuracy", st.session_state.train_accuracy)
        mlflow.sklearn.log_model(st.session_state.model, "model")

# Hi·ªÉn th·ªã k·∫øt qu·∫£ hu·∫•n luy·ªán n·∫øu c√≥
if "train_accuracy" in st.session_state:
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation: {st.session_state.train_accuracy:.4f}")
if "train_report" in st.session_state:
    st.text(st.session_state.train_report)

# ------------------------
# B∆∞·ªõc 4: Demo d·ª± ƒëo√°n
# ------------------------
st.header("4. Demo d·ª± ƒëo√°n")
uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh ch·ªØ s·ªë vi·∫øt tay", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    from PIL import Image
    if st.session_state.get("model") is None:
        st.error("B·∫°n c·∫ßn hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n!")
    else:
        if st.button("D·ª± ƒëo√°n t·ª´ ·∫£nh t·∫£i l√™n"):
            image = Image.open(uploaded_file).convert('L')
            image = image.resize((28, 28))
            img_array = np.array(image).reshape(1, -1) / 255.0
            if st.session_state.trained_model_name == "SVM" and st.session_state.get("scaler") is not None:
                img_array = st.session_state.scaler.transform(img_array)
            prediction = st.session_state.model.predict(img_array)
            st.image(image, caption="H√¨nh ·∫£nh t·∫£i l√™n", use_container_width=True)
            st.write(f"D·ª± ƒëo√°n: {prediction[0]}")

st.header("5. Tracking MLflow")

try:
    import tempfile
    import shutil
    from mlflow.tracking import MlflowClient
    client = MlflowClient()

    # L·∫•y danh s√°ch th√≠ nghi·ªám t·ª´ MLflow
    experiments = mlflow.search_experiments()

    if experiments:
        st.write("#### Danh s√°ch th√≠ nghi·ªám")
        experiment_data = []
        for exp in experiments:
            experiment_data.append({
                "Experiment ID": exp.experiment_id,
                "Experiment Name": exp.name,
                "Artifact Location": exp.artifact_location
            })
        st.dataframe(pd.DataFrame(experiment_data))

        # Ch·ªçn th√≠ nghi·ªám ƒë·ªÉ xem chi ti·∫øt
        selected_exp_id = st.selectbox(
            "üîç Ch·ªçn th√≠ nghi·ªám ƒë·ªÉ xem chi ti·∫øt",
            options=[exp.experiment_id for exp in experiments]
        )

        # L·∫•y danh s√°ch runs trong th√≠ nghi·ªám ƒë√£ ch·ªçn
        runs = mlflow.search_runs(selected_exp_id)
        if not runs.empty:
            st.write("#### Danh s√°ch runs")
            st.dataframe(runs)

            # Ch·ªçn run ƒë·ªÉ xem chi ti·∫øt
            selected_run_id = st.selectbox(
                "üîç Ch·ªçn run ƒë·ªÉ xem chi ti·∫øt",
                options=runs["run_id"]
            )

            # Hi·ªÉn th·ªã chi ti·∫øt run
            run = mlflow.get_run(selected_run_id)
            st.write("##### Th√¥ng tin run")
            st.write(f"*Run ID:* {run.info.run_id}")
            st.write(f"*Experiment ID:* {run.info.experiment_id}")
            st.write(f"*Start Time:* {run.info.start_time}")

            # Hi·ªÉn th·ªã metrics
            st.write("##### Metrics")
            st.json(run.data.metrics)

            # Hi·ªÉn th·ªã params
            st.write("##### Params")
            st.json(run.data.params)

            # Hi·ªÉn th·ªã artifacts v√† cho ph√©p t·∫£i xu·ªëng ho·∫∑c tr·ª±c quan h√≥a
            artifacts = client.list_artifacts(run.info.run_id)
            if artifacts:
                st.write("##### Artifacts")
                for artifact in artifacts:
                    try:
                        with tempfile.TemporaryDirectory() as tmp_dir:
                            artifact_path = client.download_artifacts(run.info.run_id, artifact.path, dst_path=tmp_dir)
                            local_artifact_path = shutil.copy(artifact_path, tmp_dir)
                            st.write(f"- {artifact.path}")
                            if artifact.path.endswith((".png", ".jpg", ".jpeg")):
                                st.image(local_artifact_path, caption=artifact.path)
                            elif artifact.path.endswith((".csv", ".txt")):
                                with open(local_artifact_path, "r", encoding='utf-8') as file:
                                    st.text(file.read())
                            with open(local_artifact_path, "rb") as file:
                                st.download_button(
                                    label=f"üì• T·∫£i xu·ªëng {artifact.path}",
                                    data=file.read(),
                                    file_name=artifact.path
                                )
                    except PermissionError:
                        st.error(f"Kh√¥ng th·ªÉ t·∫£i artifact do l·ªói quy·ªÅn truy c·∫≠p: {artifact.path}")
            else:
                st.warning("Kh√¥ng c√≥ artifact n√†o trong run n√†y.")
        else:
            st.warning("Kh√¥ng c√≥ runs n√†o trong th√≠ nghi·ªám n√†y.")
    else:
        st.warning("Kh√¥ng c√≥ th√≠ nghi·ªám n√†o ƒë∆∞·ª£c t√¨m th·∫•y.")
except Exception as e:
    st.error(f"ƒê√£ x·∫£y ra l·ªói khi l·∫•y danh s√°ch th√≠ nghi·ªám: {e}")
